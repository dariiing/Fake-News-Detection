{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import the preprocessed ISOT dataset",
   "id": "8c967188b7db9412"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:14.469163Z",
     "start_time": "2025-01-05T13:44:13.965875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files={'train': \"preprocessed_isot/isot_train.csv\", 'test': \"preprocessed_isot/isot_test.csv\"})\n",
    "print(dataset)"
   ],
   "id": "35f3f8cb0d176635",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['statement', 'label'],\n",
      "        num_rows: 8578\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['statement', 'label'],\n",
      "        num_rows: 16713\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pick the pre-trained model",
   "id": "b517a9d59eb42e76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:14.474079Z",
     "start_time": "2025-01-05T13:44:14.471060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"albert/albert-base-v2\"\n",
    "your_path = 'isot_new_results'"
   ],
   "id": "7e5dd0e4d414bb8c",
   "outputs": [],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Look over the label distribution",
   "id": "b4a1917732497053"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:14.486730Z",
     "start_time": "2025-01-05T13:44:14.475088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_label_distribution = Counter(dataset['train']['label'])\n",
    "test_label_distribution = Counter(dataset['test']['label'])\n",
    "\n",
    "print(\"Training Label Distribution:\", train_label_distribution)\n",
    "print(\"Test Label Distribution:\", test_label_distribution)"
   ],
   "id": "93a4c785ef92b56d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Distribution: Counter({False: 4310, True: 4268})\n",
      "Test Label Distribution: Counter({True: 8528, False: 8185})\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Labels in their original form are strings (true/false). We need to convert them to numerical values so they can be processed by the model.",
   "id": "22adf2174484ab0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:14.503906Z",
     "start_time": "2025-01-05T13:44:14.486730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(dataset['train']['label'])\n",
    "\n",
    "def encode_labels(example):\n",
    "    return {'encoded_label': label_encoder.transform([example['label']])[0]}\n",
    "\n",
    "for split in dataset:\n",
    "    dataset[split] = dataset[split].map(encode_labels, batched=False)"
   ],
   "id": "119cfede3e42a1a0",
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The id2label and label2id mappings in AutoConfig are used to inform the model of the specific label-to-ID mappings so we can get the actual label names rather than the numerical reps when we do inference with the model.",
   "id": "5235ccf546e00f40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:14.733497Z",
     "start_time": "2025-01-05T13:44:14.503906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "unique_labels = sorted(list(set(dataset['train']['label'])))\n",
    "id2label = {i: label for i, label in enumerate(unique_labels)}\n",
    "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.id2label = id2label\n",
    "config.label2id = label2id\n"
   ],
   "id": "74e36377950e72f5",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Verify the correct labels are being used",
   "id": "c3ae7f0e40d930d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:14.736626Z",
     "start_time": "2025-01-05T13:44:14.733497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"ID to Label Mapping:\", config.id2label)\n",
    "print(\"Label to ID Mapping:\", config.label2id)"
   ],
   "id": "2408315af31a0c8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID to Label Mapping: {0: False, 1: True}\n",
      "Label to ID Mapping: {False: 0, True: 1}\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4302a4edd5f344dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we need to tokenize the text data so it can be processed by the model. We will use the tokenizer that corresponds to the model we are using from Hugging Face's Transformers library.",
   "id": "5474992b3860f0fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:15.017474Z",
     "start_time": "2025-01-05T13:44:14.736626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AlbertForSequenceClassification, AlbertTokenizer\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
    "model = AlbertForSequenceClassification.from_pretrained(model_name, config=config)\n"
   ],
   "id": "4e36576eb2017537",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We need to filter out any examples that have invalid content (e.g. empty strings) before tokenizing the data. Then, we will encode the labels and tokenize the text data. Tokenizing means converting the text data into numerical representations that can be processed by the model.",
   "id": "9c96fd96434c097a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:15.024045Z",
     "start_time": "2025-01-05T13:44:15.017474Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset)",
   "id": "4f276f3395cecd06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['statement', 'label', 'encoded_label'],\n",
      "        num_rows: 8578\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['statement', 'label', 'encoded_label'],\n",
      "        num_rows: 16713\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:15.056172Z",
     "start_time": "2025-01-05T13:44:15.025287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def filter_invalid_content(example):\n",
    "    return isinstance(example['statement'], str)\n",
    "\n",
    "dataset = dataset.filter(filter_invalid_content, batched=False)\n",
    "\n",
    "def encode_data(batch):\n",
    "    tokenized_inputs = tokenizer(batch[\"statement\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "    tokenized_inputs[\"labels\"] = batch[\"encoded_label\"]\n",
    "    return tokenized_inputs\n",
    "\n",
    "dataset_encoded = dataset.map(encode_data, batched=True)"
   ],
   "id": "7f27f8afbaeda6a5",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Verify the data is tokenized correctly:",
   "id": "973e8f2b24dbe374"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:15.060310Z",
     "start_time": "2025-01-05T13:44:15.057177Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset_encoded)",
   "id": "95fa4f366efcae17",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['statement', 'label', 'encoded_label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 8578\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['statement', 'label', 'encoded_label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 16713\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The DataCollatorWithPadding ensures that all input sequences in a batch are padded to the same length, using the padding logic defined by the tokenizer. This is necessary because the model can only process inputs of the same length.",
   "id": "51966d61db6c9e28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:15.063357Z",
     "start_time": "2025-01-05T13:44:15.060310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ],
   "id": "44e5507bc487e0a0",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next we'll set up LabelEncoder to encode labels and defines a function to compute per-label accuracy from a confusion matrix, providing label-specific accuracy metrics. I.e. when we train the model we want to see the accuracy metrics per label as well as the average metrics. This is more relevant if you have more than two labels, and one is underperforming. ",
   "id": "b3b532b39e3f67bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:15.067872Z",
     "start_time": "2025-01-05T13:44:15.064361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(unique_labels)\n",
    "\n",
    "def per_label_accuracy(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    correct_predictions = cm.diagonal()\n",
    "    label_totals = cm.sum(axis=1)\n",
    "    per_label_acc = np.divide(correct_predictions, label_totals, out=np.zeros_like(correct_predictions, dtype=float), where=label_totals != 0)\n",
    "    return dict(zip(labels, per_label_acc))"
   ],
   "id": "6631dde6b29a5f95",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compute the following metrics: accuracy, precision, recall, f1 score, and per-label accuracy.",
   "id": "e1dbb72b88c986ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:15.072536Z",
     "start_time": "2025-01-05T13:44:15.068385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    decoded_labels = label_encoder.inverse_transform(labels)\n",
    "    decoded_preds = label_encoder.inverse_transform(preds)\n",
    "\n",
    "    precision = precision_score(decoded_labels, decoded_preds, average='weighted')\n",
    "    recall = recall_score(decoded_labels, decoded_preds, average='weighted')\n",
    "    f1 = f1_score(decoded_labels, decoded_preds, average='weighted')\n",
    "    acc = accuracy_score(decoded_labels, decoded_preds)\n",
    "\n",
    "    labels_list = list(label_encoder.classes_)\n",
    "    per_label_acc = per_label_accuracy(decoded_labels, decoded_preds, labels_list)\n",
    "\n",
    "    per_label_acc_metrics = {}\n",
    "    for label, accuracy in per_label_acc.items():\n",
    "        label_key = f\"accuracy_label_{label}\"\n",
    "        per_label_acc_metrics[label_key] = accuracy\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        **per_label_acc_metrics\n",
    "    }"
   ],
   "id": "dbc426b92f30f17e",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, the training begins. Training loss and validation loss should decrease consistenly. If the training loss is decreasing but the validation loss is increasing, the model is overfitting. If both are increasing, the model is underfitting.",
   "id": "89b117a85c9dd98e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:44:15.076607Z",
     "start_time": "2025-01-05T13:44:15.073543Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset_encoded['train'][0])\n",
   "id": "3e347236e4ba3167",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'statement': 'louisville, ky. (reuters) - three people who claim they were assaulted at a donald trump rally in louisville, kentucky, last month have filed a lawsuit against the republican presidential candidate, saying he “incited a riot.” molly shah, kashiya nwanguma and henry brousseau filed the lawsuit on thursday in jefferson circuit court in louisville, claiming that trump’s repeated calls of “get them out” at a rally at the kentucky international convention center on march 1 was intended to direct his supporters to “use unwanted, harmful physical force to remove protesters, including the plaintiffs.” the lawsuit also names as defendants the trump campaign and three individuals who the plaintiffs claim assaulted them at the rally. the three plaintiffs, all louisville residents, claim they suffered physical injuries, emotional distress and humiliation, and are seeking unspecified damages, according to the lawsuit. “peaceful protest is an american tradition, especially in the context of presidential politics,” dan canon, the attorney for the plaintiffs, told reuters in a twitter message. “but what you see all over the country, time and time again, is violence employed against protesters at trump campaign events. these plaintiffs are saying ‘enough is enough,’” the lawsuit said trump stopped his 30-minute speech five times to point out protesters and, in most cases, told supporters to “get ‘em out of here,” according to the lawsuit. a spokeswoman for trump’s campaign could not be reached for comment. the lawsuit claims that trump “incited a riot as defined under the kentucky penal code.” the individuals named as defendants are matthew heimbach, described in the complaint as a trump supporter and ohio resident who is “affiliated with the traditionalist worker party, a recognized hate group”; alvin bamberger, 75, described as a trump supporter and an ohio resident; and an unknown female. according to the lawsuit, at the rally, heimbach, who was wearing a traditionalist worker party t-shirt, attacked shah and nwanguma. a spokesman for the traditional worker party could not be reached. a website for the traditionalist worker party describes it as a grassroots political organization that believes, among other things, that “european-american identity is under constant attack.” the southern poverty law center, a non-profit organization that monitors groups it considers extremist, classifies the traditionalist worker party as a white nationalist hate group. according to the lawsuit, nwanguma was assaulted by numerous protesters at the rally, of whom heimbach and bamberger were the most aggressive. video of nwanguma, a 21-year-old college student, being repeatedly pushed at the convention went viral after the rally, the lawsuit said. bamberger could not be reached immediately for comment. the lawsuit also claims that shah was assaulted by heimbach and that brousseau was assaulted by the unknown female defendant.', 'label': True, 'encoded_label': 1, 'input_ids': [2, 13223, 15, 5766, 9, 13, 5, 139, 21458, 18, 6, 13, 8, 132, 148, 72, 2632, 59, 46, 20252, 35, 21, 5159, 7095, 6950, 19, 13223, 15, 4425, 15, 236, 1617, 57, 5263, 21, 8022, 149, 14, 2235, 3389, 2316, 15, 1148, 24, 13, 1, 108, 10424, 43, 21, 10597, 9, 1, 10064, 4396, 15, 13, 22940, 1046, 13, 103, 9967, 6401, 17, 1010, 334, 28357, 1346, 5263, 14, 8022, 27, 8775, 19, 6811, 3343, 495, 19, 13223, 15, 5865, 30, 7095, 1, 18, 4251, 3029, 16, 13, 1, 3060, 105, 70, 1, 35, 21, 6950, 35, 14, 4425, 294, 3087, 459, 27, 285, 137, 23, 2081, 20, 1744, 33, 5955, 20, 13, 1, 3699, 21095, 15, 20297, 1825, 558, 20, 4681, 14558, 15, 215, 14, 16328, 18, 9, 1, 14, 8022, 67, 1817, 28, 19270, 14, 7095, 1150, 17, 132, 1883, 72, 14, 16328, 18, 2632, 20252, 105, 35, 14, 6950, 9, 14, 132, 16328, 18, 15, 65, 13223, 2175, 15, 2632, 59, 2537, 1825, 5368, 15, 6090, 13402, 17, 23622, 15, 17, 50, 5246, 27005, 15184, 15, 496, 20, 14, 8022, 9, 13, 1, 18025, 1566, 4569, 25, 40, 189, 2876, 15, 1118, 19, 14, 4141, 16, 3389, 2634, 15, 1, 1685, 5742, 15, 14, 2925, 26, 14, 16328, 18, 15, 470, 27853, 19, 21, 10623, 2802, 9, 13, 1, 811, 98, 42, 196, 65, 84, 14, 475, 15, 85, 17, 85, 188, 15, 25, 3300, 3390, 149, 14558, 35, 7095, 1150, 963, 9, 158, 16328, 18, 50, 1148, 13, 1, 23680, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 1}\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T13:47:34.071248Z",
     "start_time": "2025-01-05T13:47:33.564034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./output',\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=500,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    save_steps=1000,\n",
    "    gradient_accumulation_steps=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_encoded['train'],\n",
    "    eval_dataset=dataset_encoded['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "af40704b3d471dce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([16])) must be the same as input size (torch.Size([16, 2]))",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[124], line 29\u001B[0m\n\u001B[0;32m      4\u001B[0m training_args \u001B[38;5;241m=\u001B[39m TrainingArguments(\n\u001B[0;32m      5\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./output\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      6\u001B[0m     num_train_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     16\u001B[0m     gradient_accumulation_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     17\u001B[0m )\n\u001B[0;32m     19\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m     20\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     21\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     26\u001B[0m     data_collator\u001B[38;5;241m=\u001B[39mdata_collator,\n\u001B[0;32m     27\u001B[0m )\n\u001B[1;32m---> 29\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\fakes\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2164\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   2162\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   2163\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2165\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2166\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2167\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2168\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2169\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\fakes\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2524\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2517\u001B[0m context \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   2518\u001B[0m     functools\u001B[38;5;241m.\u001B[39mpartial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mno_sync, model\u001B[38;5;241m=\u001B[39mmodel)\n\u001B[0;32m   2519\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(batch_samples) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   2520\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mdistributed_type \u001B[38;5;241m!=\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mDEEPSPEED\n\u001B[0;32m   2521\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m contextlib\u001B[38;5;241m.\u001B[39mnullcontext\n\u001B[0;32m   2522\u001B[0m )\n\u001B[0;32m   2523\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[1;32m-> 2524\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2526\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2527\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   2528\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[0;32m   2529\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   2530\u001B[0m ):\n\u001B[0;32m   2531\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   2532\u001B[0m     tr_loss \u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m+\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32m~\\Desktop\\fakes\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3654\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(self, model, inputs, num_items_in_batch)\u001B[0m\n\u001B[0;32m   3651\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_mb\u001B[38;5;241m.\u001B[39mreduce_mean()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m   3653\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_loss_context_manager():\n\u001B[1;32m-> 3654\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3656\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m inputs\n\u001B[0;32m   3657\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   3658\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mtorch_empty_cache_steps \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   3659\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mtorch_empty_cache_steps \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   3660\u001B[0m ):\n",
      "File \u001B[1;32m~\\Desktop\\fakes\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3708\u001B[0m, in \u001B[0;36mTrainer.compute_loss\u001B[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001B[0m\n\u001B[0;32m   3706\u001B[0m         loss_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_items_in_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m num_items_in_batch\n\u001B[0;32m   3707\u001B[0m     inputs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mloss_kwargs}\n\u001B[1;32m-> 3708\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3709\u001B[0m \u001B[38;5;66;03m# Save past state if it exists\u001B[39;00m\n\u001B[0;32m   3710\u001B[0m \u001B[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001B[39;00m\n\u001B[0;32m   3711\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mpast_index \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\Desktop\\fakes\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\fakes\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\Desktop\\fakes\\.venv\\Lib\\site-packages\\transformers\\models\\albert\\modeling_albert.py:1182\u001B[0m, in \u001B[0;36mAlbertForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1180\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mproblem_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti_label_classification\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1181\u001B[0m         loss_fct \u001B[38;5;241m=\u001B[39m BCEWithLogitsLoss()\n\u001B[1;32m-> 1182\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[43mloss_fct\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict:\n\u001B[0;32m   1185\u001B[0m     output \u001B[38;5;241m=\u001B[39m (logits,) \u001B[38;5;241m+\u001B[39m outputs[\u001B[38;5;241m2\u001B[39m:]\n",
      "File \u001B[1;32m~\\Desktop\\fakes\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\fakes\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\Desktop\\fakes\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:819\u001B[0m, in \u001B[0;36mBCEWithLogitsLoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m    818\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 819\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbinary_cross_entropy_with_logits\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    820\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    821\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    822\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    823\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpos_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\fakes\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:3624\u001B[0m, in \u001B[0;36mbinary_cross_entropy_with_logits\u001B[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001B[0m\n\u001B[0;32m   3621\u001B[0m     reduction_enum \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction)\n\u001B[0;32m   3623\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (target\u001B[38;5;241m.\u001B[39msize() \u001B[38;5;241m==\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize()):\n\u001B[1;32m-> 3624\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   3625\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTarget size (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;241m.\u001B[39msize()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) must be the same as input size (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   3626\u001B[0m     )\n\u001B[0;32m   3628\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mbinary_cross_entropy_with_logits(\n\u001B[0;32m   3629\u001B[0m     \u001B[38;5;28minput\u001B[39m, target, weight, pos_weight, reduction_enum\n\u001B[0;32m   3630\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: Target size (torch.Size([16])) must be the same as input size (torch.Size([16, 2]))"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save the results, the model and the state of the model.",
   "id": "312c99b9c0d8561d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer.evaluate()\n",
    "trainer.save_model(your_path)\n",
    "trainer.save_state()"
   ],
   "id": "2488383c06dfedb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "id": "3f23cd771109c911",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
